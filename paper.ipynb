{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b666c5",
   "metadata": {},
   "source": [
    "## Code Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60a490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi, floor, ceil\n",
    "from itertools import combinations, product\n",
    "from uuid import uuid4 as uuid\n",
    "from random import randrange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import HTML\n",
    "from bokeh.io import output_notebook, export_png\n",
    "from bokeh.plotting import figure, ColumnDataSource, show\n",
    "from bokeh.layouts import gridplot, column, layout, Spacer\n",
    "from bokeh.models import HoverTool, LinearColorMapper, NumeralTickFormatter, ColorBar\n",
    "from bokeh.models.tickers import BasicTicker\n",
    "from bokeh.palettes import Blues9 as blues, Oranges9 as oranges, Greys256 as greys, Category20_20 as category_palette\n",
    "from bokeh.transform import dodge\n",
    "from scipy.stats import chi2_contingency as two_way_chi_square\n",
    "\n",
    "pd.set_option('display.float_format', (lambda x: f'{x:.4f}' if x > 0.0001 else f'{x:.2e}'))\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "FOR_VIEWING = False\n",
    "EXPORT_TO_PNG = True\n",
    "ATTRIBUTES = ['race', 'sex', 'first_gen_status']\n",
    "CATEGORIES = ['reflection', 'focus', 'organization', 'argument', 'writing']\n",
    "\n",
    "\n",
    "if 'HIDE_CODE_INJECTED' not in locals():\n",
    "    display(HTML('''\n",
    "        <script>\n",
    "            function code_toggle(button) {\n",
    "                let cell = button;\n",
    "                while (!cell.matches(\".cell\")) {\n",
    "                    cell = cell.parentElement;\n",
    "                }\n",
    "                let input = null;\n",
    "                for (const child of cell.children) {\n",
    "                    if (child.matches(\".input\")) {\n",
    "                        input = child;\n",
    "                        break;\n",
    "                    }\n",
    "                }\n",
    "                if (input.style.display === \"none\") {\n",
    "                    button.innerHTML = \"Hide Code\";\n",
    "                    input.style.display = \"\";\n",
    "                } else {\n",
    "                    input.style.display = \"none\";\n",
    "                    button.innerHTML = \"Show Code\";\n",
    "                }\n",
    "            }\n",
    "        </script>\n",
    "    '''))\n",
    "    HIDE_CODE_INJECTED = True\n",
    "\n",
    "def hide_code():\n",
    "    if not FOR_VIEWING:\n",
    "        return\n",
    "    uid = uuid()\n",
    "    display(HTML(f'''\n",
    "        <button id=\"{uid}\" onclick=\"javascript:code_toggle(this);\"></button>\n",
    "        <script>\n",
    "            setTimeout(function () {{\n",
    "                code_toggle(document.getElementById(\"{uid}\"));\n",
    "            }}, 500);\n",
    "        </script>\n",
    "    '''))\n",
    "\n",
    "def grade_to_gpa(grade):\n",
    "    if grade is np.nan:\n",
    "        return np.nan\n",
    "    elif grade[0] == 'S':\n",
    "        return 3\n",
    "    elif grade[0] == 'U':\n",
    "        return 0\n",
    "    elif grade[0] not in 'ABCDF' or not (len(grade) < 2 or grade[1] in '+-'):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return 'FDCBA'.index(grade[0]) + (0 if len(grade) < 2 else (0.6 * ('-+'.index(grade[1]) - 0.5)))\n",
    "\n",
    "def show_plot(fig, filename):\n",
    "    show(fig)\n",
    "    if EXPORT_TO_PNG:\n",
    "        def recur_notool(fig):\n",
    "            if hasattr(fig, 'toolbar'):\n",
    "                fig.toolbar.logo = None\n",
    "                fig.toolbar_location = None\n",
    "            elif hasattr(fig, 'children'):\n",
    "                for child in fig.children:\n",
    "                    recur_notool(child)\n",
    "        recur_notool(fig)\n",
    "        export_png(fig, filename=f'output-images/{filename}')\n",
    "\n",
    "def read_twe_data():\n",
    "    raw_df = pd.read_excel('demographics.xlsx', sheet_name='2015-2019')\n",
    "    df = raw_df[['Fall Rubric Score', 'Spring Rubric Score', 'Blue Book', 'YEAR', 'RACE', 'SEX', 'FIRSTGEN', 'CSP_FallGRADE', 'CSP_SpringGRADE']].copy()\n",
    "    df.columns = ['fall_score', 'spring_score', 'twe', 'year', 'race', 'sex', 'first_gen', 'fall_grade', 'spring_grade']\n",
    "    df['assessment'] = 'twe'\n",
    "    df['first_gen_status'] = df['first_gen'].map(lambda value: 'First Gen' if value == 'Y' else 'Not First Gen')\n",
    "    df['sex'] = df['sex'].map(lambda value: 'Female' if value == 'F' else 'Male')\n",
    "    df['fall_gpa'] = df['fall_grade'].map(grade_to_gpa)\n",
    "    df['spring_gpa'] = df['spring_grade'].map(grade_to_gpa)\n",
    "    df['fall_pass'] = df['fall_score'].map(lambda score: score > 3)\n",
    "    df['spring_pass'] = df['spring_score'].map(lambda score: score > 3)\n",
    "    df['eval_pass'] = df['twe'] > 3\n",
    "    df['pass'] = (\n",
    "        ((df['fall_score'] > 3) & (df['spring_score'] > 3))\n",
    "        | ((df['fall_score'] > 3) & (df['twe'] > 3))\n",
    "        | ((df['spring_score'] > 3) & (df['twe'] > 3))\n",
    "    )\n",
    "    df['overall_pass'] = df['pass']\n",
    "    df = df[[\n",
    "        'assessment',\n",
    "        'year', 'race', 'sex', 'first_gen_status',\n",
    "        'fall_grade', 'fall_gpa',\n",
    "        'spring_grade', 'spring_gpa',\n",
    "        'fall_score', 'spring_score', 'twe',\n",
    "        'fall_pass', 'spring_pass', 'eval_pass', 'pass', 'overall_pass',\n",
    "    ]]\n",
    "    return df\n",
    "\n",
    "def read_portfolio_data():\n",
    "    raw_df = pd.read_excel('demographics.xlsx', sheet_name='2020-2023')\n",
    "    df = raw_df[['low score', 'high score', 'adjudicator score', 'YEAR', 'RACE', 'SEX', 'FIRSTGEN', 'CSP_FallGRADE', 'CSP_SpringGRADE']].copy()\n",
    "    df.columns = ['low', 'high', 'tiebreaker', 'year', 'race', 'sex', 'first_gen', 'fall_grade', 'spring_grade']\n",
    "    df['assessment'] = 'portfolio'\n",
    "    df['first_gen_status'] = df['first_gen'].map(lambda value: 'First Gen' if value == 'Y' else 'Not First Gen')\n",
    "    df['sex'] = df['sex'].map(lambda value: 'Female' if value == 'F' else 'Male')\n",
    "    df['race'] = df['race'].replace({\n",
    "        'Black/African A': 'Black or African American',\n",
    "        'Hispanic/Latinx': 'Hispanic or Latino',\n",
    "        'International': 'Non Resident Alien',\n",
    "        'Native Hawaiian': 'Native Hawaiian or Other Pacific Islander',\n",
    "        'Two or More': 'Two or More Races',\n",
    "    })\n",
    "    df['fall_gpa'] = df['fall_grade'].map(grade_to_gpa)\n",
    "    df['spring_gpa'] = df['spring_grade'].map(grade_to_gpa)\n",
    "    df = df.replace('-', np.nan)\n",
    "    df['tiebreaker'] = pd.to_numeric(df['tiebreaker'])\n",
    "    df['median'] = df[['low', 'high', 'tiebreaker']].median(axis=1, numeric_only=True)\n",
    "    df['fall_pass'] = df['fall_gpa'].map(lambda gpa: gpa > 2)\n",
    "    df['spring_pass'] = df['spring_gpa'].map(lambda gpa: gpa > 2)\n",
    "    df['eval_pass'] = df['median'] >= 3\n",
    "    # drop students who did not turn in their portfolios\n",
    "    df = df[(~df['low'].isna()) & (~df['high'].isna())]\n",
    "    df['pass'] = df['fall_pass'] & df['spring_pass'] & df['eval_pass']\n",
    "    df['overall_pass'] = df['pass']\n",
    "    df = df[[\n",
    "        'assessment',\n",
    "        'year', 'race', 'sex', 'first_gen_status',\n",
    "        'fall_grade', 'fall_gpa',\n",
    "        'spring_grade', 'spring_gpa',\n",
    "        'low', 'high', 'tiebreaker', 'median',\n",
    "        'fall_pass', 'spring_pass', 'eval_pass', 'pass', 'overall_pass',\n",
    "    ]]\n",
    "    return df\n",
    "\n",
    "TWE_DATA = read_twe_data()\n",
    "PORT_DATA = read_portfolio_data()\n",
    "ATTR_VALUES = {\n",
    "    attr: tuple(\n",
    "        pd.concat([TWE_DATA[attr], PORT_DATA[attr]])\n",
    "        .value_counts()\n",
    "        .sort_values(ascending=False)\n",
    "        .index\n",
    "    )\n",
    "    for attr in ATTRIBUTES\n",
    "}\n",
    "ATTR_VALUES['year'] = sorted([*TWE_DATA['year'].unique(), *PORT_DATA['year'].unique()])\n",
    "COLOR_MAPS = {\n",
    "    'race': {\n",
    "        'White': category_palette[4],\n",
    "        'Hispanic or Latino': category_palette[10],\n",
    "        'Asian': category_palette[2],\n",
    "        'Two or More Races': category_palette[8],\n",
    "        'Non Resident Alien': category_palette[0],\n",
    "        'Black or African American': category_palette[14],\n",
    "        'Unknown': category_palette[12],\n",
    "        'Native Hawaiian or Other Pacific Islander': category_palette[6],\n",
    "    },\n",
    "    'sex': {\n",
    "        'Female': category_palette[7],\n",
    "        'Male': category_palette[1],\n",
    "    },\n",
    "    'first_gen_status': {\n",
    "        'Not First Gen': category_palette[1],\n",
    "        'First Gen': category_palette[3],\n",
    "    },\n",
    "}\n",
    "\n",
    "hide_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5405c4",
   "metadata": {},
   "source": [
    "## Sanity Check: College Demographics Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e37ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_demographics(attr):\n",
    "    attr_df = pd.concat([\n",
    "        TWE_DATA.groupby(['year', attr]).count()['fall_grade'],\n",
    "        PORT_DATA.groupby(['year', attr]).count()['fall_grade'],\n",
    "    ])\n",
    "    attr_df = attr_df.unstack(attr, fill_value=0)\n",
    "    attr_df['All'] = attr_df.sum(axis=1)\n",
    "    attr_df = pd.concat(\n",
    "        [\n",
    "            attr_df.stack(),\n",
    "            (2 * attr_df.div(attr_df.sum(axis=1), axis=0)).stack(),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).rename(columns={0:'count', 1:'percent'}).reset_index()\n",
    "\n",
    "    fig = figure(\n",
    "        width=960, height=480,\n",
    "        x_range=ATTR_VALUES['year'], y_range=[0, 600],\n",
    "        title=f'{attr.title().replace(\"_\", \" \")} Distribution of Cohorts',\n",
    "        x_axis_label='Cohort',\n",
    "    )\n",
    "    year_width = 0.9\n",
    "    renderers = []\n",
    "    renderer = fig.vbar(\n",
    "        x='year',\n",
    "        top='count',\n",
    "        width=year_width,\n",
    "        color='#C0C0C0',\n",
    "        fill_alpha=0.5,\n",
    "        source=ColumnDataSource(attr_df[attr_df[attr] == 'All']),\n",
    "        legend_label='All',\n",
    "    )\n",
    "    renderers.append(renderer)\n",
    "    num_attr_vals = len(ATTR_VALUES[attr])\n",
    "    dodge_offsets = [\n",
    "        i * year_width / num_attr_vals + ((num_attr_vals + 1 ) % 2) * (year_width / num_attr_vals / 2)\n",
    "        for i in range(-num_attr_vals // 2, num_attr_vals // 2 )\n",
    "    ]\n",
    "    dodge_width = year_width / num_attr_vals - 0.01\n",
    "    for i, attr_val in enumerate(ATTR_VALUES[attr]):\n",
    "        renderer = fig.vbar(\n",
    "            x=dodge('year', dodge_offsets[i], range=fig.x_range),\n",
    "            top='count',\n",
    "            width=dodge_width,\n",
    "            color=COLOR_MAPS[attr][attr_val],\n",
    "            source=ColumnDataSource(attr_df[attr_df[attr] == attr_val]),\n",
    "            legend_label=attr_val,\n",
    "        )\n",
    "        renderers.append(renderer)\n",
    "\n",
    "    fig.add_tools(HoverTool(renderers=renderers, tooltips=[\n",
    "        ('Cohort', '@year'),\n",
    "        (attr.replace('_', ' ').title(), f'@{attr}'),\n",
    "        ('Count', '@count'),\n",
    "        ('Percent', '@percent{0.00%}'),\n",
    "    ]))\n",
    "    years_before = len(TWE_DATA['year'].unique())\n",
    "    fig.line(\n",
    "        x=[years_before, years_before],\n",
    "        y=[0, 1000],\n",
    "        color='black',\n",
    "        line_width=1.5,\n",
    "        line_dash='dashed',\n",
    "    )\n",
    "    fig.xgrid.visible = False\n",
    "    fig.ygrid.visible = False\n",
    "    fig.legend.location = 'top_left'\n",
    "    show_plot(fig, filename=f'0-demographic-sanity-{attr}.png')\n",
    "\n",
    "hide_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68660b45",
   "metadata": {},
   "source": [
    "The plots here do not directly say anything about the writing assessment, but they lay the groundwork for the demographic analysis we do later. In particular, these plots show that the demographics before and after the change in assessment are not significantly different. The exception is for the 2020-2021 academic year, which was completely remote due to the COVID-19 pandemic. This led to an overall decrease in enrollment, as well as a reduction in Asian and non-resident alien students. The distribution of sex and first-generation status of students was not significantly affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demographics('race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62243b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demographics('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb5b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demographics('first_gen_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0bb6a",
   "metadata": {},
   "source": [
    "## Curricular Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe69527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_course_pass_rate():\n",
    "    df = pd.concat([\n",
    "        TWE_DATA[['year', 'assessment', 'fall_pass', 'spring_pass', 'eval_pass', 'overall_pass', 'pass']],\n",
    "        PORT_DATA[['year', 'assessment', 'fall_pass', 'spring_pass', 'eval_pass', 'overall_pass', 'pass']],\n",
    "    ])\n",
    "    eval_types = {\n",
    "        'fall': ('Fall Semester Score/Grade', category_palette[0]),\n",
    "        'spring': ('Spring Semester Score/Grade', category_palette[4]),\n",
    "        'eval': ('Non-Course Evaluation (TWE/Portfolio)', category_palette[2]),\n",
    "        'overall': ('Overall FYW Assessment', '#000000'),\n",
    "    }\n",
    "    plot_df = pd.concat([\n",
    "        df.pivot_table(\n",
    "            index=['year', 'assessment'],\n",
    "            columns=[f'{eval_type}_pass'],\n",
    "            values=['pass'],\n",
    "            aggfunc=len,\n",
    "        )\n",
    "        .reset_index()\n",
    "        .set_axis(['year', 'assessment', 'fail', 'pass'], axis=1)\n",
    "        .assign(\n",
    "            total=(lambda df: df['pass'] + df['fail']),\n",
    "            pass_portion=(lambda df: df['pass'] / df['total']),\n",
    "            eval_type=eval_type,\n",
    "        )\n",
    "        for i, eval_type in enumerate(eval_types)\n",
    "    ])\n",
    "    fig = figure(\n",
    "        width=960, height=480,\n",
    "        x_range=sorted(plot_df['year'].unique()),\n",
    "        y_range=[0, 1],\n",
    "        title='Pass Rates of FYW Assessment Components',\n",
    "    )\n",
    "    for eval_type in eval_types:\n",
    "        fig.square(\n",
    "            x='year',\n",
    "            y='pass_portion',\n",
    "            source=ColumnDataSource(plot_df[plot_df['eval_type'] == eval_type]),\n",
    "            legend_label=eval_types[eval_type][0],\n",
    "            color=eval_types[eval_type][1],\n",
    "        )\n",
    "        fig.line(\n",
    "            x='year',\n",
    "            y='pass_portion',\n",
    "            color=eval_types[eval_type][1],\n",
    "            source=ColumnDataSource(plot_df[plot_df['eval_type'] == eval_type]),\n",
    "        )\n",
    "    fig.line(\n",
    "        x=[4, 4],\n",
    "        y=[0, 600],\n",
    "        color='black',\n",
    "        line_dash='dashed',\n",
    "    )\n",
    "    fig.yaxis.formatter = NumeralTickFormatter(format='0 %')\n",
    "    fig.legend.location = 'bottom_right'\n",
    "    show_plot(fig, filename='1-curricular-component-pass-rates.png')\n",
    "\n",
    "def plot_outcome_flow():\n",
    "    display(\n",
    "        pd.concat([\n",
    "            TWE_DATA[['year', 'assessment', 'fall_pass', 'spring_pass', 'eval_pass', 'pass']],\n",
    "            PORT_DATA[['year', 'assessment', 'fall_pass', 'spring_pass', 'eval_pass', 'pass']],\n",
    "        ])\n",
    "        .assign(\n",
    "            courses_passed=(lambda df: df['fall_pass'].astype(int) + df['spring_pass'].astype(int)),\n",
    "        )\n",
    "        .pivot_table(\n",
    "            index=['courses_passed', 'assessment'],\n",
    "            columns=['eval_pass'],\n",
    "            values=['year'],\n",
    "            aggfunc=len,\n",
    "            fill_value=0,\n",
    "        )\n",
    "        .reset_index()\n",
    "        .assign(\n",
    "            pass_rate=(lambda df: df[('year', True)] / (df[('year', True)] + df[('year', False)])),\n",
    "        )\n",
    "        .droplevel(1, axis=1)\n",
    "        #[['courses_passed', 'assessment', 'pass_rate']]\n",
    "        .pivot_table(\n",
    "            index=['courses_passed'],\n",
    "            columns=['assessment'],\n",
    "            values=['pass_rate'],\n",
    "        )\n",
    "        .sort_values(['courses_passed'], ascending=False)\n",
    "        .sort_index(axis=1, ascending=False)\n",
    "    )\n",
    "\n",
    "hide_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f04449",
   "metadata": {},
   "source": [
    "### Pass Rate of FYW Assessment Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4dd5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_course_pass_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1fc47",
   "metadata": {},
   "source": [
    "FIXME scatter plot matrix of TWE\n",
    "\n",
    "This should show that the increase in TWE pass rate doesn't help anyone - almost everyone who pass the TWE that way would have passed the two FYS courses anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ce300",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outcome_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ff52ed",
   "metadata": {},
   "source": [
    "fundamental contradiction: is the TWE/portfolio supposed to align with courses, or to provide an independent third evaluation?\n",
    "* if the former, should correlate with course grade\n",
    "* if the later, should have lower correlation (due to _independence_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbaf401",
   "metadata": {},
   "source": [
    "## Performance Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e354fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_rate_df(attr, overall):\n",
    "    indices = ['assessment', 'year']\n",
    "    if attr is not None:\n",
    "        indices.append(attr)\n",
    "    return (\n",
    "        pd.concat([\n",
    "            TWE_DATA.pivot_table(\n",
    "                index=indices,\n",
    "                columns=[('pass' if overall else 'eval_pass')],\n",
    "                values=['fall_grade'],\n",
    "                aggfunc=len,\n",
    "                fill_value=0,\n",
    "            ),\n",
    "            PORT_DATA.pivot_table(\n",
    "                index=indices,\n",
    "                columns=[('pass' if overall else 'eval_pass')],\n",
    "                values=['fall_grade'],\n",
    "                aggfunc=len,\n",
    "                fill_value=0,\n",
    "            )\n",
    "        ])\n",
    "        .reset_index()\n",
    "        .set_axis([*indices, 'failed', 'passed'], axis=1)\n",
    "        .assign(\n",
    "            count=(lambda df: df['passed'] + df['failed']),\n",
    "            passed_percent=(lambda df: df['passed'] / (df['passed'] + df['failed'])),\n",
    "            failed_percent=(lambda df: df['failed'] / (df['passed'] + df['failed'])),\n",
    "        )\n",
    "    )\n",
    "\n",
    "def plot_pass_rates(attr=None, overall=True, row_size=1, legend_location='bottom_left'):\n",
    "    attr_df = pass_rate_df(attr, overall)\n",
    "    fig = figure(\n",
    "        width=960 // row_size, height=480 // row_size,\n",
    "        x_range=ATTR_VALUES['year'], y_range=[0, 1],\n",
    "        title=' '.join([\n",
    "            ('Overall FYW Assessment' if overall else 'Non-Course Evaluation'),\n",
    "            'Pass Rate by',\n",
    "            ('' if attr is None else attr.title().replace('_', ' ')),\n",
    "        ]),\n",
    "        x_axis_label='Cohort',\n",
    "    )\n",
    "    renderers = []\n",
    "    if attr is not None:\n",
    "        for attr_val in ATTR_VALUES[attr]:\n",
    "            if attr_val in ['Unknown', 'Native Hawaiian or Other Pacific Islander']:\n",
    "                continue\n",
    "            renderer = fig.square(\n",
    "                x='year',\n",
    "                y='passed_percent',\n",
    "                color=COLOR_MAPS[attr][attr_val],\n",
    "                source=ColumnDataSource(attr_df[attr_df[attr] == attr_val]),\n",
    "                legend_label=attr_val,\n",
    "            )\n",
    "            fig.line(\n",
    "                x='year',\n",
    "                y='passed_percent',\n",
    "                color=COLOR_MAPS[attr][attr_val],\n",
    "                source=ColumnDataSource(attr_df[attr_df[attr] == attr_val]),\n",
    "            )\n",
    "            renderers.append(renderer)\n",
    "    renderer = fig.square(\n",
    "        x='year',\n",
    "        y='passed_percent',\n",
    "        size=8,\n",
    "        source=ColumnDataSource(pass_rate_df(None, overall)),\n",
    "        color='#000000',\n",
    "        legend_label='All Students',\n",
    "    )\n",
    "    fig.line(\n",
    "        x='year',\n",
    "        y='passed_percent',\n",
    "        line_width=1.5,\n",
    "        line_dash='dashed',\n",
    "        color='#000000',\n",
    "        source=ColumnDataSource(pass_rate_df(None, overall)),\n",
    "    )\n",
    "    renderers.append(renderer)\n",
    "    fig.add_tools(HoverTool(renderers=renderers, tooltips=[\n",
    "        ('Cohort', '@year'),\n",
    "        ('Race', f'@{attr}'),\n",
    "        ('Count', '@count'),\n",
    "        ('Pass Rate', '@passed_percent{0%}')\n",
    "    ]))\n",
    "    fig.line(\n",
    "        x=[4, 4],\n",
    "        y=[0, 600],\n",
    "        color='black',\n",
    "        line_dash='dashed',\n",
    "    )\n",
    "    fig.yaxis.formatter = NumeralTickFormatter(format='0 %')\n",
    "    fig.legend.location = legend_location\n",
    "    fig.legend.items = [fig.legend.items[-1], *fig.legend.items[:-1]]\n",
    "    return fig\n",
    "\n",
    "def chi_square_pass_rate_between_assessments(attr, overall, attr_val=None):\n",
    "    df = pass_rate_df(attr, overall)\n",
    "    if attr_val is not None:\n",
    "        df = df[df[attr] == attr_val]\n",
    "    observations = df.groupby('assessment')[['failed', 'passed']].sum()\n",
    "    observations = observations.to_numpy()\n",
    "    return two_way_chi_square(observations)\n",
    "\n",
    "def assessment_chi_square_results(attr, overall, p_level=0.01):\n",
    "    data = []\n",
    "    for attr_val in ATTR_VALUES[attr]:\n",
    "        chi_square, p, _, _ = chi_square_pass_rate_between_assessments(attr, overall, attr_val)\n",
    "        data.append([attr_val, chi_square, p])\n",
    "    results_df = pd.DataFrame(data, columns=[attr, 'chi_square', 'p-value'])\n",
    "    results_df['significant'] = results_df['p-value'] < p_level\n",
    "    return (\n",
    "        results_df[[attr, 'p-value', 'significant']]\n",
    "        .set_index([attr])\n",
    "        .replace({True: 'Yes', False: 'No'})\n",
    "    )\n",
    "\n",
    "def chi_square_pass_rate_between_demographics(assessment, attr, overall, attr_val=None):\n",
    "    df = pass_rate_df(attr, overall)\n",
    "    df = df[df['assessment'] == assessment]\n",
    "    observations = df.groupby(attr)[['failed', 'passed']].sum()\n",
    "    if attr_val is not None:\n",
    "        if attr_val not in observations.index:\n",
    "            return np.nan, np.nan, np.nan, None\n",
    "        observations = observations.loc[[attr_val, ATTR_VALUES[attr][0]]].to_numpy()\n",
    "    else:\n",
    "        observations = observations.to_numpy()\n",
    "    return two_way_chi_square(observations)\n",
    "\n",
    "\n",
    "def demographic_chi_square_results(attr, overall, p_level=0.01):\n",
    "    data = []\n",
    "    for attr_val in ATTR_VALUES[attr][1:]:\n",
    "        for assessment in ['twe', 'portfolio']:\n",
    "            chi_square, p, _, _ = chi_square_pass_rate_between_demographics(assessment, attr, overall, attr_val)\n",
    "            data.append([assessment, attr_val, chi_square, p])\n",
    "    results_df = pd.DataFrame(data, columns=['assessment', attr, 'chi_square', 'p-value'])\n",
    "    results_df['significant'] = results_df['p-value'] < p_level\n",
    "    results_df = results_df[[attr, 'assessment', 'p-value', 'significant']].set_index([attr, 'assessment'])\n",
    "    results_df = results_df.rename_axis('results', axis=1)\n",
    "    return (\n",
    "        results_df\n",
    "        .unstack('assessment')\n",
    "        .swaplevel('results', 'assessment', axis=1)\n",
    "        .sort_index(axis=1, level=['assessment', 'results'], ascending=[False, True])\n",
    "        .sort_values(\n",
    "            ['race'],\n",
    "            key=(lambda series: series.map(lambda value: ATTR_VALUES[attr].index(value)))\n",
    "        )\n",
    "        .replace({True: 'Yes', False: 'No'})\n",
    "    )\n",
    "\n",
    "hide_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51736d69",
   "metadata": {},
   "source": [
    "Here we look at the overall pass rate and whether that differs by demographic attributes. We are specifically interested in two questions:\n",
    "\n",
    "1. Did the change in assessment lead to a change in pass rate?\n",
    "2. Are there differences in pass rates between races, sexes, and first-generation students?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29022a2",
   "metadata": {},
   "source": [
    "### Pass Rates for Non-Course Assessment (TWE and Portfolio) by Race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f66ccb",
   "metadata": {},
   "source": [
    "Here we are interested in whether a portfolio-based evaluation is more representative of student ability than a TWE-based evaluation. A simple metric for answering this question is looking at the percentage of students who pass the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a10a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plot(\n",
    "    plot_pass_rates(\n",
    "        overall=False,\n",
    "        attr='race',\n",
    "        legend_location='top_left',\n",
    "    ),\n",
    "    filename='2-performance-eval-by-race.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435680f",
   "metadata": {},
   "source": [
    "Note that the Native Hawaiian or Other Pacific Islander population is small (never more than two a year), hence the dramatic changes it exhibits.\n",
    "\n",
    "It is immediately obvious that switching to a portfolio-based evaluation had a substantial impact on pass rates for all students, regardless of race. We can confirm this statistically with a chi-square test of independence. In our case, our null hypothesis is that the evaluation method is independent of pass rate, which is to say pass rate is _not_ correlated with whether the TWE or the portfolio was used. A low p-value (p < 0.01) would reject the null hypothesis, suggesting that the evaluation method _does_ have an effect on pass rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b80340",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_chi_square_results('race', overall=False, p_level=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec7a83",
   "metadata": {},
   "source": [
    "As expected, these results show that the change to a portfolio-based evaluation led to significant changes in the pass rates for all races, with the exception for students identified as Native Hawaiian or Other Pacific Islander or of unknown race, of which there are too few for the chi-square test to be meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4323ee5",
   "metadata": {},
   "source": [
    "Both of these p-values are below the p-level of 0.01, meaning that for both TWE and portfolio assessments, race _does_ have an effect on pass rate. We can further explore which race(s) have pass rates that differ significantly from the pass rates of white students by performing pairwise chi-square tests. Since we already know there will be significant results, we apply the Bonferroni correction to use a p-level of 0.01 / 7 ~= 0.00143, which raises the standard for finding a result significant. In this case, the null hypothesis is that race _does not_ have an effect on pass rate compared to white students; a low p-value (p < 0.01) would reject the null hypothesis, suggesting that race _does_ have an effect on pass rate compared to white students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_chi_square_results('race', overall=True, p_level=0.00143)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a42fc",
   "metadata": {},
   "source": [
    "FIXME description of these results\n",
    "* does a higher P-value after the change in assessment mean anything? I don't think so, hence the next test\n",
    "\n",
    "We could also look at whether the change in assessment led to differences in pass rates. The null hypothesis here is that the assessment method _does not_ have an effect on pass rate; a low p-value (p < 0.01) would reject the null hypothesis, suggesting that the assessment _does_ have an effect on pass rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fdab1d",
   "metadata": {},
   "source": [
    "Comparatively, the pass rates for sex and first-generation status are clearer, where male students and first-generation students have lower pass rates than female and non-first-generation students respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plot(\n",
    "    gridplot([[\n",
    "        plot_pass_rates('sex', overall=True, row_size=2),\n",
    "        plot_pass_rates('first_gen_status', overall=True, row_size=2),\n",
    "    ]]),\n",
    "    filename='2-performance-overall-gender-gen.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4bbe6",
   "metadata": {},
   "source": [
    "Although unnecessary, the chi-square tests confirm that sex and first-generation status do affect pass rates, with p-values < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe22113",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_pass_rate_between_demographics('twe', 'sex', overall=True).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e35885",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_pass_rate_between_demographics('twe', 'first_gen_status', overall=True).pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938990b0",
   "metadata": {},
   "source": [
    "## Reliability Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_assessments():\n",
    "    return pd.concat([\n",
    "        (\n",
    "            pd.read_csv('assessments.csv', sep='\\t')\n",
    "            .assign(\n",
    "                total=(lambda df: sum(\n",
    "                    df[col] for col in \n",
    "                    ['reflection', 'focus', 'organization', 'argument', 'writing']\n",
    "                )),\n",
    "                tiebreaker=False,\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            pd.read_csv('tiebreakers.csv', sep='\\t')\n",
    "            .assign(tiebreaker=True)\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "ASS_DF = read_assessments()\n",
    "\n",
    "def intra_category_agreement():\n",
    "    display(\n",
    "        pd.concat(\n",
    "            [\n",
    "                (\n",
    "                    ASS_DF[['student', *CATEGORIES]]\n",
    "                    .dropna()\n",
    "                    .set_index(['student'])\n",
    "                    .stack()\n",
    "                    .reset_index()\n",
    "                    .rename(columns={'level_1':'category', 0:'score'})\n",
    "                    .groupby(['student', 'category']).aggregate(['count', 'mean'])\n",
    "                    .droplevel(0, axis=1)\n",
    "                    .where(lambda df: df['count'] == 2)\n",
    "                    .dropna()\n",
    "                    .drop(columns=['count'])\n",
    "                    .replace({0:'same', 0.5:'diff', 1:'same'})\n",
    "                    .reset_index()\n",
    "                    .groupby(['category', 'mean']).aggregate(['count'])\n",
    "                    .unstack()\n",
    "                    .droplevel([0, 1], axis=1)\n",
    "                    .assign(\n",
    "                        total=(lambda df: df['diff'] + df['same']),\n",
    "                        same_proportion=(lambda df: df['same'] / df['total']),\n",
    "                        diff_proportion=(lambda df: df['diff'] / df['total']),\n",
    "                    )\n",
    "                ),\n",
    "                (\n",
    "                    ASS_DF[[*CATEGORIES]]\n",
    "                    .dropna()\n",
    "                    .aggregate(['sum', 'count'])\n",
    "                    .transpose()\n",
    "                    .assign(\n",
    "                        pass_rate=(lambda df: df['sum'] / df['count']),\n",
    "                    )\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        .sort_index(key=(lambda index: index.map(CATEGORIES.index)))\n",
    "        [['pass_rate', 'same_proportion']]\n",
    "        .transpose()\n",
    "    )\n",
    "\n",
    "def inter_category_correlation():\n",
    "    INITIAL_MAP = {category: category[0].upper() for category in CATEGORIES}\n",
    "    choosing_df = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                (\n",
    "                    ASS_DF[ASS_DF['cohort'] == '2022-2023']\n",
    "                    .groupby(['assessor'])['cohort'].count()\n",
    "                ),\n",
    "                (\n",
    "                    ASS_DF[ASS_DF['cohort'] == '2022-2023']\n",
    "                    .groupby(['assessor'])[CATEGORIES].corr()\n",
    "                    .stack()\n",
    "                    .reset_index()\n",
    "                    .rename(columns={'level_1':'x', 'level_2':'y', 0:'corr'})\n",
    "                    .assign(\n",
    "                        x_index=(lambda df: df['x'].apply(lambda s: list(INITIAL_MAP.keys()).index(s))),\n",
    "                        y_index=(lambda df: df['y'].apply(lambda s: list(INITIAL_MAP.keys()).index(s))),\n",
    "                    )\n",
    "                    .loc[lambda df: df['x_index'] > df['y_index']]\n",
    "                    .groupby(['assessor'])['corr'].describe()\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        .rename(columns={'cohort':'n'})\n",
    "        .loc[lambda df: (20 < df['n']) & (df['n'] < 30)]\n",
    "        .loc[lambda df: df['count'] == 10]\n",
    "        .reset_index()\n",
    "    )\n",
    "    chosen = [\n",
    "        # assessor with the most positively correlated categories\n",
    "        choosing_df.sort_values(['max'], ascending=[False]).iloc[0]['assessor'],\n",
    "        # assessor with the lowest all-possitive correlations\n",
    "        choosing_df[choosing_df['min'] > 0].sort_values(['max'], ascending=[True]).iloc[0]['assessor'],\n",
    "        # assessor with the smallest standard deviation\n",
    "        choosing_df.sort_values(['std'], ascending=[True]).iloc[0]['assessor'],\n",
    "        # assessor with the most negatively correlated categories\n",
    "        choosing_df.sort_values(['min'], ascending=[True]).iloc[0]['assessor'],\n",
    "    ]\n",
    "    gridrow = []\n",
    "    color_mapper = LinearColorMapper(palette=[*oranges, *reversed(blues)], low=-1, high=1)\n",
    "    for i, assessor in enumerate([None, *chosen]):\n",
    "        assessor_df = (\n",
    "            ASS_DF[\n",
    "                (ASS_DF['cohort'] == '2022-2023')\n",
    "                & (not assessor or (ASS_DF['assessor'] == assessor))\n",
    "            ][CATEGORIES].corr()\n",
    "            .unstack()\n",
    "            .reset_index()\n",
    "            .rename(columns={'level_0':'x', 'level_1':'y', 0:'corr'})\n",
    "            .assign(\n",
    "                x_index=(lambda df: df['x'].apply(lambda s: list(INITIAL_MAP.keys()).index(s))),\n",
    "                y_index=(lambda df: df['y'].apply(lambda s: list(INITIAL_MAP.keys()).index(s))),\n",
    "            )\n",
    "            .loc[lambda df: df['x_index'] > df['y_index']]\n",
    "            .assign(\n",
    "                x_initial=(lambda df: df['x'].apply(lambda s: INITIAL_MAP[s])),\n",
    "                y_initial=(lambda df: df['y'].apply(lambda s: INITIAL_MAP[s])),\n",
    "            )\n",
    "        )\n",
    "        if assessor:\n",
    "            n = choosing_df.set_index(['assessor']).at[assessor, 'n']\n",
    "            title = f'Assessor #{i} (n={n})'\n",
    "            #title = f'{assessor} (n={n})'\n",
    "        else:\n",
    "            n = len(ASS_DF[ASS_DF['cohort'] == '2022-2023'].dropna())\n",
    "            title = f'Overall (n={n})'\n",
    "        fig = figure(\n",
    "            height=175, width=175,\n",
    "            x_range=list(INITIAL_MAP.values())[1:],\n",
    "            y_range=list(reversed(INITIAL_MAP.values()))[1:],\n",
    "            title=title,\n",
    "        )\n",
    "        fig.rect(\n",
    "            x=0,\n",
    "            y=0,\n",
    "            width=10,\n",
    "            height=10,\n",
    "            color='#808080',\n",
    "        )\n",
    "        fig.rect(\n",
    "            x='x_initial',\n",
    "            y='y_initial',\n",
    "            width=1, height=1,\n",
    "            fill_color={\n",
    "                'field': 'corr',\n",
    "                'transform': color_mapper,\n",
    "            },\n",
    "            line_color=None,\n",
    "            source=ColumnDataSource(assessor_df),\n",
    "        )\n",
    "        gridrow.append(fig)\n",
    "    fig = figure(frame_width=0, height=350)\n",
    "    fig.rect(\n",
    "        x=0,\n",
    "        y=0,\n",
    "        width=10,\n",
    "        height=10,\n",
    "        color='#808080',\n",
    "    )\n",
    "    fig.axis.visible = False\n",
    "    fig.add_layout(\n",
    "        ColorBar(\n",
    "            color_mapper=color_mapper,\n",
    "            formatter=NumeralTickFormatter(format='0.00'),\n",
    "        ),\n",
    "        'right',\n",
    "    )\n",
    "    gridrow.append(fig)\n",
    "    show_plot(\n",
    "        layout([[\n",
    "            column(gridrow[0], Spacer()),\n",
    "            column(gridrow[1], gridrow[3]),\n",
    "            column(gridrow[2], gridrow[4]),\n",
    "            gridrow[5],\n",
    "        ]]),\n",
    "        filename='3-reliability-category-correlation.png'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64428532",
   "metadata": {},
   "source": [
    "### Category Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e624651",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_category_agreement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5876a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_category_correlation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
