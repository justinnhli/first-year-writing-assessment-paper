{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b666c5",
   "metadata": {},
   "source": [
    "## Code Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60a490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi, floor, ceil\n",
    "from itertools import combinations, product\n",
    "from time import monotonic_ns\n",
    "from random import randrange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import HTML\n",
    "from bokeh.io import output_notebook, export_png\n",
    "from bokeh.plotting import figure, ColumnDataSource, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import HoverTool, LinearColorMapper, NumeralTickFormatter\n",
    "from bokeh.models.tickers import BasicTicker\n",
    "from bokeh.palettes import Blues9 as blues, Greys256 as greys, Category20_20 as category_palette\n",
    "from bokeh.transform import dodge\n",
    "from scipy.stats import chi2_contingency as two_way_chi_square\n",
    "\n",
    "pd.set_option('display.float_format', (lambda x: f'{x:.4f}' if x > 0.0001 else f'{x:.2e}'))\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "FOR_VIEWING = False\n",
    "EXPORT_TO_PNG = False\n",
    "ATTRIBUTES = ['race', 'sex', 'first_gen_status']\n",
    "\n",
    "def create_hide_code():\n",
    "\n",
    "    if not FOR_VIEWING:\n",
    "        return (lambda: None)\n",
    "\n",
    "    display(HTML('''\n",
    "        <script>\n",
    "            function code_toggle(button) {\n",
    "                button = $(button);\n",
    "                var input = button.parents(\".cell\").children(\".input\");\n",
    "                input.toggle()\n",
    "                if (input.css(\"display\") === \"none\") {\n",
    "                    button.html(\"Show Code\");\n",
    "                } else {\n",
    "                    button.html(\"Hide Code\");\n",
    "                }\n",
    "            }\n",
    "        </script>\n",
    "    '''))\n",
    "\n",
    "    def _hide_code():\n",
    "        timestamp = str(monotonic_ns())\n",
    "        display(HTML('''\n",
    "            <button id=\"''' + timestamp + '''\" onclick=\"javascript:code_toggle(this);\">\n",
    "                Hide Code\n",
    "            </button>\n",
    "            <script>\n",
    "                setTimeout(function () {\n",
    "                    var button = $(\"#''' + timestamp + '''\");\n",
    "                    var input = button.parents(\".cell\").children(\".input\");\n",
    "                    input.hide();\n",
    "                    button.html(\"Show Code\");\n",
    "                }, 500);\n",
    "            </script>\n",
    "        '''))\n",
    "\n",
    "    return _hide_code\n",
    "\n",
    "hide_code = create_hide_code()\n",
    "\n",
    "def grade_to_gpa(grade):\n",
    "    if grade is np.nan:\n",
    "        return np.nan\n",
    "    elif grade[0] not in 'ABCDF' or not (len(grade) < 2 or grade[1] in '+-'):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return 'FDCBA'.index(grade[0]) + (0 if len(grade) < 2 else (0.6 * ('-+'.index(grade[1]) - 0.5)))\n",
    "\n",
    "def show_plot(plot, filename):\n",
    "    show(plot)\n",
    "    if EXPORT_TO_PNG:\n",
    "        export_png(plot, filename=filename)\n",
    "\n",
    "def read_twe_data():\n",
    "    raw_df = pd.read_excel('demographics.xlsx', sheet_name='2015-2019')\n",
    "    df = raw_df[['Fall Rubric Score', 'Spring Rubric Score', 'Blue Book', 'YEAR', 'RACE', 'SEX', 'FIRSTGEN', 'CSP_FallGRADE', 'CSP_SpringGRADE']].copy()\n",
    "    df.columns = ['fall_score', 'spring_score', 'twe', 'year', 'race', 'sex', 'first_gen', 'fall_grade', 'spring_grade']\n",
    "    df['assessment'] = 'twe'\n",
    "    df['first_gen_status'] = df['first_gen'].map(lambda value: 'First Gen' if value == 'Y' else 'Not First Gen')\n",
    "    df['sex'] = df['sex'].map(lambda value: 'Female' if value == 'F' else 'Male')\n",
    "    df['fall_gpa'] = df['fall_grade'].map(grade_to_gpa)\n",
    "    df['spring_gpa'] = df['spring_grade'].map(grade_to_gpa)\n",
    "    df['fall_pass'] = df['fall_score'].map(lambda score: score > 3)\n",
    "    df['spring_pass'] = df['spring_score'].map(lambda score: score > 3)\n",
    "    df['eval_pass'] = df['twe'] > 3\n",
    "    df['pass'] = (\n",
    "        ((df['fall_score'] > 3) & (df['spring_score'] > 3))\n",
    "        | ((df['fall_score'] > 3) & (df['twe'] > 3))\n",
    "        | ((df['spring_score'] > 3) & (df['twe'] > 3))\n",
    "    )\n",
    "    df = df[[\n",
    "        'assessment',\n",
    "        'year', 'race', 'sex', 'first_gen_status',\n",
    "        'fall_grade', 'fall_gpa',\n",
    "        'spring_grade', 'spring_gpa',\n",
    "        'fall_score', 'spring_score', 'twe',\n",
    "        'fall_pass', 'spring_pass', 'eval_pass', 'pass',\n",
    "    ]]\n",
    "    return df\n",
    "\n",
    "def read_portfolio_data():\n",
    "    raw_df = pd.read_excel('demographics.xlsx', sheet_name='2020-2021')\n",
    "    df = raw_df[['low score', 'high score', 'adjudicator score', 'final determination', 'YEAR', 'RACE', 'SEX', 'FIRSTGEN', 'CSP_FallGRADE', 'CSP_SpringGRADE']].copy()\n",
    "    df.columns = ['low', 'high', 'tiebreaker', 'pass', 'year', 'race', 'sex', 'first_gen', 'fall_grade', 'spring_grade']\n",
    "    df['assessment'] = 'portfolio'\n",
    "    df['first_gen_status'] = df['first_gen'].map(lambda value: 'First Gen' if value == 'Y' else 'Not First Gen')\n",
    "    df['sex'] = df['sex'].map(lambda value: 'Female' if value == 'F' else 'Male')\n",
    "    df['fall_gpa'] = df['fall_grade'].map(grade_to_gpa)\n",
    "    df['spring_gpa'] = df['spring_grade'].map(grade_to_gpa)\n",
    "    df = df.replace('-', np.nan)\n",
    "    df['mean'] = df[['low', 'high', 'tiebreaker']].mean(axis=1, numeric_only=True)\n",
    "    df['fall_pass'] = df['fall_gpa'].map(lambda gpa: gpa > 2)\n",
    "    df['spring_pass'] = df['spring_gpa'].map(lambda gpa: gpa > 2)\n",
    "    df['eval_pass'] = df['mean'] >= 3\n",
    "    # drop students with extensions or did not turn in their portfolios\n",
    "    df = df[(df['pass'] != 'EXTENSION UNTIL 5/08/20') & (~df['low'].isna()) & (~df['high'].isna())]\n",
    "    df['pass'] = df['pass'].map(lambda value: value.lower() == 'completed')\n",
    "    df = df[[\n",
    "        'assessment',\n",
    "        'year', 'race', 'sex', 'first_gen_status',\n",
    "        'fall_grade', 'fall_gpa',\n",
    "        'spring_grade', 'spring_gpa',\n",
    "        'low', 'high', 'tiebreaker', 'mean',\n",
    "        'fall_pass', 'spring_pass', 'eval_pass', 'pass',\n",
    "    ]]\n",
    "    return df\n",
    "\n",
    "TWE_DATA = read_twe_data()\n",
    "PORT_DATA = read_portfolio_data()\n",
    "ATTR_VALUES = {\n",
    "    attr: tuple(\n",
    "        pd.concat([TWE_DATA[attr], PORT_DATA[attr]])\n",
    "        .value_counts()\n",
    "        .sort_values(ascending=False)\n",
    "        .index\n",
    "    )\n",
    "    for attr in ATTRIBUTES\n",
    "}\n",
    "ATTR_VALUES['year'] = sorted([*TWE_DATA['year'].unique(), *PORT_DATA['year'].unique()])\n",
    "COLOR_MAPS = {\n",
    "    'race': {\n",
    "        'White': category_palette[5],\n",
    "        'Hispanic or Latino': category_palette[11],\n",
    "        'Asian': category_palette[3],\n",
    "        'Two or More Races': category_palette[9],\n",
    "        'Non Resident Alien': category_palette[1],\n",
    "        'Black or African American': category_palette[15],\n",
    "        'Unknown': category_palette[13],\n",
    "        'Native Hawaiian or Other Pacific Islander': category_palette[7],\n",
    "    },\n",
    "\n",
    "    'sex': {\n",
    "        'Female': category_palette[7],\n",
    "        'Male': category_palette[1],\n",
    "    },\n",
    "    'first_gen_status': {\n",
    "        'Not First Gen': category_palette[1],\n",
    "        'First Gen': category_palette[3],\n",
    "    },\n",
    "}\n",
    "\n",
    "hide_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5405c4",
   "metadata": {},
   "source": [
    "## Sanity Check: College Demographics Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e37ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_demographics_old():\n",
    "    grid = []\n",
    "    for attr in ATTRIBUTES:\n",
    "        attr_df = pd.concat([\n",
    "            TWE_DATA.groupby(['year', attr]).count()['fall_grade'],\n",
    "            PORT_DATA.groupby(['year', attr]).count()['fall_grade'],\n",
    "        ])\n",
    "        display(attr_df.groupby([attr]).sum().sort_values() / attr_df.sum())\n",
    "        attr_df = attr_df.unstack(attr, fill_value=0).reset_index()\n",
    "        fig = figure(\n",
    "            width=960//3, height=960//3,\n",
    "            x_range=ATTR_VALUES['year'], y_range=[0, 600],\n",
    "            title=f'{attr.title().replace(\"_\", \" \")} Distribution of Cohorts',\n",
    "            x_axis_label='Cohort',\n",
    "        )\n",
    "        fig.vbar_stack(\n",
    "            ATTR_VALUES[attr],\n",
    "            x='year',\n",
    "            width=0.9,\n",
    "            color=[*COLOR_MAPS[attr].values()],\n",
    "            source=ColumnDataSource(attr_df),\n",
    "        )\n",
    "        fig.line(\n",
    "            x=[4, 4],\n",
    "            y=[0, 600],\n",
    "            color='black',\n",
    "            line_width=1.5,\n",
    "            line_dash='dashed',\n",
    "        )\n",
    "        fig.xaxis.major_label_orientation = -pi/4\n",
    "        grid.append(fig)\n",
    "    show_plot(gridplot([grid]), filename='1-demographic-baseline.png')\n",
    "\n",
    "def plot_demographics(attr):\n",
    "    attr_df = pd.concat([\n",
    "        TWE_DATA.groupby(['year', attr]).count()['fall_grade'],\n",
    "        PORT_DATA.groupby(['year', attr]).count()['fall_grade'],\n",
    "    ])\n",
    "    attr_df = attr_df.unstack(attr, fill_value=0)\n",
    "    attr_df['All'] = attr_df.sum(axis=1)\n",
    "    attr_df = pd.concat(\n",
    "        [\n",
    "            attr_df.stack(),\n",
    "            (2 * attr_df.div(attr_df.sum(axis=1), axis=0)).stack(),\n",
    "        ],\n",
    "        axis=1,\n",
    "    ).rename(columns={0:'count', 1:'percent'}).reset_index()\n",
    "\n",
    "    fig = figure(\n",
    "        width=960, height=480,\n",
    "        x_range=ATTR_VALUES['year'], y_range=[0, 600],\n",
    "        title=f'{attr.title().replace(\"_\", \" \")} Distribution of Cohorts',\n",
    "        x_axis_label='Cohort',\n",
    "    )\n",
    "    year_width = 0.9\n",
    "    renderers = []\n",
    "    renderer = fig.vbar(\n",
    "        x='year',\n",
    "        top='count',\n",
    "        width=year_width,\n",
    "        color='#C0C0C0',\n",
    "        fill_alpha=0.5,\n",
    "        source=ColumnDataSource(attr_df[attr_df[attr] == 'All']),\n",
    "        legend_label='All',\n",
    "    )\n",
    "    renderers.append(renderer)\n",
    "    num_attr_vals = len(ATTR_VALUES[attr])\n",
    "    dodge_offsets = [\n",
    "        i * year_width / num_attr_vals + ((num_attr_vals + 1 ) % 2) * (year_width / num_attr_vals / 2)\n",
    "        for i in range(-num_attr_vals // 2, num_attr_vals // 2 )\n",
    "    ]\n",
    "    dodge_width = year_width / num_attr_vals - 0.01\n",
    "    for i, attr_val in enumerate(ATTR_VALUES[attr]):\n",
    "        renderer = fig.vbar(\n",
    "            x=dodge('year', dodge_offsets[i], range=fig.x_range),\n",
    "            top='count',\n",
    "            width=dodge_width,\n",
    "            color=COLOR_MAPS[attr][attr_val],\n",
    "            source=ColumnDataSource(attr_df[attr_df[attr] == attr_val]),\n",
    "            legend_label=attr_val,\n",
    "        )\n",
    "        renderers.append(renderer)\n",
    "\n",
    "    fig.add_tools(HoverTool(renderers=renderers, tooltips=[\n",
    "        ('Cohort', '@year'),\n",
    "        (attr.replace('_', ' ').title(), f'@{attr}'),\n",
    "        ('Count', '@count'),\n",
    "        ('Percent', '@percent{0.00%}'),\n",
    "    ]))\n",
    "    years_before = len(TWE_DATA['year'].unique())\n",
    "    fig.line(\n",
    "        x=[years_before, years_before],\n",
    "        y=[0, 1000],\n",
    "        color='black',\n",
    "        line_width=1.5,\n",
    "        line_dash='dashed',\n",
    "    )\n",
    "    fig.xgrid.visible = False\n",
    "    fig.ygrid.visible = False\n",
    "    fig.legend.location = 'top_left'\n",
    "    show_plot(fig, filename=f'1-demographic-baseline-{attr}.png')\n",
    "\n",
    "hide_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68660b45",
   "metadata": {},
   "source": [
    "The plots here do not directly say anything about the writing assessment, but they lay the groundwork for the demographic analysis we do later. In particular, these plots show that the demographics before and after the change in assessment are not significantly different. The exception is for the 2020-2021 academic year, which was completely remote due to the COVID-19 pandemic. This led to an overall decrease in enrollment, as well as a reduction in Asian and non-resident alien students. The distribution of sex and first-generation status of students was not significantly affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demographics('race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62243b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demographics('sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb5b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_demographics('first_gen_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbaf401",
   "metadata": {},
   "source": [
    "## Ideological Lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4859e24",
   "metadata": {},
   "source": [
    "### Pass Rates for Non-Course Assessment (TWE and Portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e354fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_rate_df(attr, overall):\n",
    "    indices = ['assessment', 'year']\n",
    "    if attr is not None:\n",
    "        indices.append(attr)\n",
    "    return (\n",
    "        pd.concat([\n",
    "            TWE_DATA.pivot_table(\n",
    "                index=indices,\n",
    "                columns=[('pass' if overall else 'eval_pass')],\n",
    "                values=['fall_grade'],\n",
    "                aggfunc=len,\n",
    "                fill_value=0,\n",
    "            ),\n",
    "            PORT_DATA.pivot_table(\n",
    "                index=indices,\n",
    "                columns=[('pass' if overall else 'eval_pass')],\n",
    "                values=['fall_grade'],\n",
    "                aggfunc=len,\n",
    "                fill_value=0,\n",
    "            )\n",
    "        ])\n",
    "        .reset_index()\n",
    "        .set_axis([*indices, 'failed', 'passed'], axis=1)\n",
    "        .assign(\n",
    "            count=(lambda df: df['passed'] + df['failed']),\n",
    "            passed_percent=(lambda df: df['passed'] / (df['passed'] + df['failed'])),\n",
    "            failed_percent=(lambda df: df['failed'] / (df['passed'] + df['failed'])),\n",
    "        )\n",
    "    )\n",
    "\n",
    "def plot_pass_rates(attr=None, overall=True, row_size=1):\n",
    "    attr_df = pass_rate_df(attr, overall)\n",
    "    fig = figure(\n",
    "        width=960 // row_size, height=480 // row_size,\n",
    "        x_range=ATTR_VALUES['year'], y_range=[0, 1],\n",
    "        title=f'Pass Rate{\"\" if attr is None else attr.title().replace(\"_\", \" \")}',\n",
    "        x_axis_label='Cohort',\n",
    "    )\n",
    "    renderers = []\n",
    "    if attr is None:\n",
    "        renderer = fig.square(\n",
    "            x='year',\n",
    "            y='passed_percent',\n",
    "            size=8,\n",
    "            source=ColumnDataSource(attr_df),\n",
    "            legend_label='Pass Rate',\n",
    "        )\n",
    "        fig.line(\n",
    "            x='year',\n",
    "            y='passed_percent',\n",
    "            line_width=2,\n",
    "            source=ColumnDataSource(attr_df),\n",
    "        )\n",
    "        renderers.append(renderer)\n",
    "    else:\n",
    "        for attr_val in ATTR_VALUES[attr]:\n",
    "            renderer = fig.square(\n",
    "                x='year',\n",
    "                y='passed_percent',\n",
    "                size=8,\n",
    "                color=COLOR_MAPS[attr][attr_val],\n",
    "                source=ColumnDataSource(attr_df[attr_df[attr] == attr_val]),\n",
    "                legend_label=attr_val,\n",
    "            )\n",
    "            fig.line(\n",
    "                x='year',\n",
    "                y='passed_percent',\n",
    "                color=COLOR_MAPS[attr][attr_val],\n",
    "                line_width=2,\n",
    "                source=ColumnDataSource(attr_df[attr_df[attr] == attr_val]),\n",
    "            )\n",
    "            renderers.append(renderer)\n",
    "    fig.add_tools(HoverTool(renderers=renderers, tooltips=[\n",
    "        ('Cohort', '@year'),\n",
    "        ('Race', f'@{attr}'),\n",
    "        ('Count', '@count'),\n",
    "        ('Pass Rate', '@passed_percent{0%}')\n",
    "    ]))\n",
    "    fig.line(\n",
    "        x=[4, 4],\n",
    "        y=[0, 600],\n",
    "        color='black',\n",
    "        line_dash='dashed',\n",
    "    )\n",
    "    fig.yaxis.formatter = NumeralTickFormatter(format='0 %')\n",
    "    fig.legend.location = 'bottom_left'\n",
    "    return fig\n",
    "\n",
    "def chi_square_pass_rate_between_assessments(attr, overall, attr_val=None):\n",
    "    df = pass_rate_df(attr, overall)\n",
    "    if attr_val is not None:\n",
    "        df = df[df[attr] == attr_val]\n",
    "    observations = df.groupby('assessment')[['failed', 'passed']].sum()\n",
    "    observations = observations.to_numpy()\n",
    "    return two_way_chi_square(observations)\n",
    "\n",
    "def assessment_chi_square_results(attr, overall, p_level=0.01):\n",
    "    data = []\n",
    "    for attr_val in ATTR_VALUES[attr]:\n",
    "        chi_square, p, _, _ = chi_square_pass_rate_between_assessments(attr, overall, attr_val)\n",
    "        data.append([attr_val, chi_square, p])\n",
    "    results_df = pd.DataFrame(data, columns=[attr, 'chi_square', 'p'])\n",
    "    results_df['significant'] = results_df['p'] < p_level\n",
    "    return results_df[[attr, 'p', 'significant']].set_index([attr])\n",
    "\n",
    "hide_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f66ccb",
   "metadata": {},
   "source": [
    "Here we are interested in whether a portfolio-based evaluation is more representative of student ability than a TWE-based evaluation. A simple metric for answering this question is looking at the percentage of students who pass the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a10a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plot_pass_rates(overall=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0bb6a",
   "metadata": {},
   "source": [
    "## Curricular Lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f04449",
   "metadata": {},
   "source": [
    "### Pass Rate of Fall and Spring FYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4dd5d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_course_pass_rate():\n",
    "    df = pd.concat([\n",
    "        TWE_DATA[['year', 'assessment', 'fall_pass', 'spring_pass', 'eval_pass']],\n",
    "        PORT_DATA[['year', 'assessment', 'fall_pass', 'spring_pass', 'eval_pass']],\n",
    "    ])\n",
    "    eval_types = ['fall', 'spring', 'eval']\n",
    "    dfs = []\n",
    "    for i, eval_type in enumerate(eval_types):\n",
    "        dfs.append(\n",
    "            df.pivot_table(\n",
    "                index=['year', 'assessment'],\n",
    "                columns=[f'{eval_type}_pass'],\n",
    "                values=[f'{eval_types[(i + 1) % len(eval_types)]}_pass'],\n",
    "                aggfunc=len,\n",
    "            )\n",
    "            .reset_index()\n",
    "            .set_axis(['year', 'assessment', 'fail', 'pass'], axis=1)\n",
    "            .assign(\n",
    "                total=(lambda df: df['pass'] + df['fail']),\n",
    "                pass_portion=(lambda df: df['pass'] / df['total']),\n",
    "                eval_type=eval_type,\n",
    "            )\n",
    "        )\n",
    "    df = pd.concat(dfs)\n",
    "    fig = figure(\n",
    "        x_range=sorted(df['year'].unique()),\n",
    "        y_range=[0, 1],\n",
    "    )\n",
    "    for eval_type in eval_types:\n",
    "        fig.square(\n",
    "            x='year',\n",
    "            y='pass_portion',\n",
    "            source=ColumnDataSource(df[df['eval_type'] == eval_type]),\n",
    "            legend_label=eval_type,\n",
    "        )\n",
    "        fig.line(\n",
    "            x='year',\n",
    "            y='pass_portion',\n",
    "            source=ColumnDataSource(df[df['eval_type'] == eval_type]),\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "show(plot_course_pass_rate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1fc47",
   "metadata": {},
   "source": [
    "FIXME scatter plot matrix of TWE\n",
    "\n",
    "This should show that the increase in TWE pass rate doesn't help anyone - almost everyone who pass the TWE that way would have passed the two FYS courses anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ce300",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_matrix_twe():\n",
    "    with pd.option_context('display.float_format', '{:.2f}'.format):\n",
    "        display(\n",
    "            pd.concat([\n",
    "                TWE_DATA[['year', 'assessment', 'fall_pass', 'spring_pass', 'eval_pass', 'pass']],\n",
    "                PORT_DATA[['year', 'assessment', 'fall_pass', 'spring_pass', 'eval_pass', 'pass']],\n",
    "            ])\n",
    "            .groupby(['assessment', 'eval_pass', 'fall_pass', 'spring_pass', 'pass']).count()\n",
    "            ['year']\n",
    "            .reset_index()\n",
    "            .rename(columns={'year':'count'})\n",
    "            .assign(\n",
    "                course_pass=(lambda df: df.apply(\n",
    "                    (lambda row:\n",
    "                        'neither' if not (row['fall_pass'] or row['spring_pass'])\n",
    "                        else (\n",
    "                            'both' if row['fall_pass'] and row['spring_pass']\n",
    "                            else 'one'\n",
    "                        )\n",
    "                    ),\n",
    "                    axis=1,\n",
    "                )),\n",
    "            )\n",
    "            .pivot_table(\n",
    "                index=['pass', 'course_pass', 'eval_pass'],\n",
    "                columns=['assessment'],\n",
    "                values=['count'],\n",
    "                fill_value=0,\n",
    "            )\n",
    "            .reset_index()\n",
    "            .set_axis(['pass', 'course_pass', 'eval_pass', 'port_count', 'twe_count'], axis=1)\n",
    "            .assign(\n",
    "                port_portion=(lambda df: df['port_count'] / df['port_count'].sum()),\n",
    "                twe_portion=(lambda df: df['twe_count'] / df['twe_count'].sum()),\n",
    "                diff=(lambda df: df['port_portion'] - df['twe_portion']),\n",
    "            )\n",
    "            [['course_pass', 'eval_pass', 'pass', 'twe_portion', 'port_portion', 'diff']]\n",
    "        )\n",
    "\n",
    "hide_code()\n",
    "plot_matrix_twe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ff52ed",
   "metadata": {},
   "source": [
    "fundamental contradiction: is the TWE/portfolio supposed to align with courses, or to provide an independent third evaluation?\n",
    "* if the former, should correlate with course grade\n",
    "* if the later, should have lower correlation (due to _independence_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844ceaa",
   "metadata": {},
   "source": [
    "## Performance Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_pass_rate_between_demographics(assessment, attr, overall, attr_val=None):\n",
    "    df = pass_rate_df(attr, overall)\n",
    "    df = df[df['assessment'] == assessment]\n",
    "    observations = df.groupby(attr)[['failed', 'passed']].sum()\n",
    "    if attr_val is not None:\n",
    "        if attr_val not in observations.index:\n",
    "            return np.nan, np.nan, np.nan, None\n",
    "        observations = observations.loc[[attr_val, ATTR_VALUES[attr][0]]].to_numpy()\n",
    "    else:\n",
    "        observations = observations.to_numpy()\n",
    "    return two_way_chi_square(observations)\n",
    "\n",
    "\n",
    "def demographic_chi_square_results(attr, overall, p_level=0.01):\n",
    "    data = []\n",
    "    for attr_val in ATTR_VALUES[attr][1:]:\n",
    "        for assessment in ['twe', 'portfolio']:\n",
    "            chi_square, p, _, _ = chi_square_pass_rate_between_demographics(assessment, attr, overall, attr_val)\n",
    "            data.append([assessment, attr_val, chi_square, p])\n",
    "    results_df = pd.DataFrame(data, columns=['assessment', attr, 'chi_square', 'p'])\n",
    "    results_df['significant'] = results_df['p'] < p_level\n",
    "    return results_df[[attr, 'assessment', 'p', 'significant']].set_index([attr, 'assessment'])\n",
    "\n",
    "hide_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7111a",
   "metadata": {},
   "source": [
    "for TWE: two raters, if both pass/fail, will take low score\n",
    "if split score, will just use third score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c694ffd",
   "metadata": {},
   "source": [
    "### Pass Rates for Non-Course Assessment (TWE and Portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d428222",
   "metadata": {},
   "source": [
    "### Pass Rate for Overall Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478acab0",
   "metadata": {},
   "source": [
    "### Pass Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51736d69",
   "metadata": {},
   "source": [
    "Here we look at the overall pass rate and whether that differs by demographic attributes. We are specifically interested in two questions:\n",
    "\n",
    "1. Are there differences in pass rates between races, sexes, and first-generation students?\n",
    "2. Did the change in assessment lead to a change in pass rate?\n",
    "\n",
    "We first look at the pass rate by race in the TWE versus the portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00213ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plot_pass_rates('race', overall=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435680f",
   "metadata": {},
   "source": [
    "Note that the Native Hawaiian or Other Pacific Islander population is small (never more than two a year), hence the dramatic changes it exhibits.\n",
    "\n",
    "It is immediately obvious that switching to a portfolio-based evaluation had a substantial impact on pass rates for all students, regardless of race. We can confirm this statistically with a chi-square test of independence. In our case, our null hypothesis is that the evaluation method is independent of pass rate, which is to say pass rate is _not_ correlated with whether the TWE or the portfolio was used. A low p-value (p < 0.01) would reject the null hypothesis, suggesting that the evaluation method _does_ have an effect on pass rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b80340",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_chi_square_results('race', overall=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec7a83",
   "metadata": {},
   "source": [
    "As expected, these results show that the change to a portfolio-based evaluation led to significant changes in the pass rates for all races, with the exception for students identified as Native Hawaiian or Other Pacific Islander or of unknown race, of which there are too few for the chi-square test to be meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc996117",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457d151",
   "metadata": {},
   "source": [
    "We first look at the pass rate by race:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77618ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(plot_pass_rates('race', overall=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e4f65",
   "metadata": {},
   "source": [
    "At a glance, the only significant difference in pass rates is for non-resident aliens, who seem to have a lower pass rate than other students both before and after the change in assessment. This appearance, however, can be deceiving. To better quantify whether race plays a role in the pass rate, we can use a chi-square test of independence. In our case, our null hypothesis is that race is independent of pass rate, which is to say that a student's race is _not_ correlated with whether they will pass. A low p-value (p < 0.01) would reject the null hypothesis, suggesting that race _does_ have an effect on pass rate.\n",
    "\n",
    "Since like must be compared against like, we look at the old TWE assessment and the new portfolio assessment separately, and aggregate over all years when that specific assessment was used. Performing the chi-square test on the TWE results gives a p-value of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_pass_rate_between_demographics('twe', 'race', overall=True).pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab7ede",
   "metadata": {},
   "source": [
    "Performing the chi-square test on the portfolio results gives a p-value of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_pass_rate_between_demographics('portfolio', 'race', overall=True).pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4323ee5",
   "metadata": {},
   "source": [
    "Both of these p-values are below the p-level of 0.01, meaning that for both TWE and portfolio assessments, race _does_ have an effect on pass rate. We can further explore which race(s) have pass rates that differ significantly from the pass rates of white students by performing pairwise chi-square tests. Since we already know there will be significant results, we apply the Bonferroni correction to use a p-level of 0.01 / 7 ~= 0.00143, which raises the standard for finding a result significant. In this case, the null hypothesis is that race _does not_ have an effect on pass rate compared to white students; a low p-value (p < 0.01) would reject the null hypothesis, suggesting that race _does_ have an effect on pass rate compared to white students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6399c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "demographic_chi_square_results('race', overall=True, p_level=0.00143)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a42fc",
   "metadata": {},
   "source": [
    "FIXME description of these results\n",
    "* does a higher P-value after the change in assessment mean anything? I don't think so, hence the next test\n",
    "\n",
    "We could also look at whether the change in assessment led to differences in pass rates. The null hypothesis here is that the assessment method _does not_ have an effect on pass rate; a low p-value (p < 0.01) would reject the null hypothesis, suggesting that the assessment _does_ have an effect on pass rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32628828",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_chi_square_results('race', overall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fdab1d",
   "metadata": {},
   "source": [
    "FIXME description of these results\n",
    "\n",
    "Comparatively, the pass rates for sex and first-generation status are clearer, where male students and first-generation students have lower pass rates than female and non-first-generation students respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(gridplot([[\n",
    "    plot_pass_rates('sex', overall=True, row_size=2),\n",
    "    plot_pass_rates('first_gen_status', overall=True, row_size=2),\n",
    "]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4bbe6",
   "metadata": {},
   "source": [
    "Although unnecessary, the chi-square tests confirm that sex and first-generation status do affect pass rates, with p-values < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe22113",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_pass_rate_between_demographics('twe', 'sex', overall=True).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e35885",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_pass_rate_between_demographics('twe', 'first_gen_status', overall=True).pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b75f7c5",
   "metadata": {},
   "source": [
    "Similarly, it is also clear that the change from TWE to portfolio did not effect pass rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e29f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_chi_square_results('sex', overall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89633021",
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_chi_square_results('first_gen_status', overall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1d7b2",
   "metadata": {},
   "source": [
    "### Rubric Category Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea18d1b",
   "metadata": {},
   "source": [
    "[This is interesting, but potentially irrelevant for this paper.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888443d",
   "metadata": {},
   "source": [
    "## Feedback Lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a70e7",
   "metadata": {},
   "source": [
    "The \"feedback\" lens can be seen as a combination of the ecological lens and FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacff73c",
   "metadata": {},
   "source": [
    "### Grade Correlation with Assessment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551fe00f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GRADES = ['F', 'D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A']\n",
    "\n",
    "def _kendalls_tau(pairs):\n",
    "    concordant = 0\n",
    "    discordant = 0\n",
    "    for (x1, y1), (x2, y2) in combinations(pairs, 2):\n",
    "        if x1 == x2 or y1 == y2:\n",
    "            continue\n",
    "        elif x1 < x2 and y1 < y2:\n",
    "            concordant += 1\n",
    "        elif x1 > x2 and y1 > y2:\n",
    "            concordant += 1\n",
    "        else:\n",
    "            discordant += 1\n",
    "    n = len(pairs)\n",
    "    return (concordant - discordant) / (n * (n - 1) / 2)\n",
    "\n",
    "def kendalls_tau(df, semester):\n",
    "    return _kendalls_tau(list(df[[f'{semester}_gpa', 'mod_score']].itertuples(index=False)))\n",
    "\n",
    "def create_fys_correlation_df(df, assessment, split_fn=None):\n",
    "    heatmap_df = df[df['assessment'] == assessment].copy()\n",
    "    if split_fn is None:\n",
    "        heatmap_df['mod_score'] = heatmap_df['score']\n",
    "    else:\n",
    "        heatmap_df['mod_score'] = heatmap_df['score'].map(split_fn)\n",
    "    return heatmap_df\n",
    "\n",
    "def create_fys_correlation_plot(df, assessment, semester):\n",
    "    heatmap_df = create_fys_correlation_df(df, assessment)\n",
    "    tau = kendalls_tau(heatmap_df, semester)\n",
    "    heatmap_df = heatmap_df.groupby([f'{semester}_grade', 'mod_score']).count()['assessment'].reset_index().rename(columns={'assessment':'count'})\n",
    "    heatmap_df['text'] = heatmap_df['count'].map(str)\n",
    "    if assessment == 'twe':\n",
    "        assessment_name = 'TWE'\n",
    "    else:\n",
    "        assessment_name = 'Portfolio'\n",
    "    fig = figure(\n",
    "        width=960//2, height=int((6/11)*(960//2)),\n",
    "        x_range=GRADES, y_range=[-0.5, 5.5],\n",
    "        match_aspect=True,\n",
    "        title=f'Correlation between {semester.title()} Grade and {assessment_name} Score (tau = {tau:.3f})',\n",
    "    )\n",
    "    fig.rect(x=0, y=0, width=100, height=100, fill_color=blues[-1])\n",
    "    fig.rect(\n",
    "        x=f'{semester}_grade',\n",
    "        y='mod_score',\n",
    "        width=1, height=(1 if assessment == 'twe' else 0.5),\n",
    "        fill_color={\n",
    "            'field': 'count',\n",
    "            'transform': LinearColorMapper(palette=[*reversed(blues)], low=1, high=heatmap_df['count'].max()),\n",
    "        },\n",
    "        line_color=None,\n",
    "        source=ColumnDataSource(heatmap_df),\n",
    "    )\n",
    "    fig.text(\n",
    "        x=f'{semester}_grade',\n",
    "        y='mod_score',\n",
    "        text='text',\n",
    "        source=ColumnDataSource(heatmap_df),\n",
    "        text_align='center',\n",
    "        text_baseline='middle',\n",
    "        text_color={\n",
    "            'field': 'count',\n",
    "            'transform': LinearColorMapper(palette=(greys[:50] + greys[-50:]), low=1, high=heatmap_df['count'].max()),\n",
    "        },\n",
    "        text_font_size='18px',\n",
    "        y_offset=2,\n",
    "    )\n",
    "    fig.yaxis.ticker = BasicTicker(num_minor_ticks=(1 if assessment == 'twe' else 2))\n",
    "    return fig\n",
    "\n",
    "def plot_fys_correlations():\n",
    "    fys_df = pd.concat([\n",
    "        TWE_DATA[['assessment', 'fall_grade', 'fall_gpa', 'spring_grade', 'spring_gpa', 'twe']].rename(columns={'twe':'score'}),\n",
    "        PORT_DATA[['assessment', 'fall_grade', 'fall_gpa', 'spring_grade', 'spring_gpa', 'mean']].rename(columns={'mean':'score'}),\n",
    "    ])\n",
    "    fys_df = fys_df.dropna() # FIXME why is this necessary?\n",
    "    grid = [[],[]]\n",
    "    for i, (assessment, semester) in enumerate(product(['twe', 'portfolio'], ['fall', 'spring'])):\n",
    "        grid[i//2].append(create_fys_correlation_plot(fys_df, assessment, semester))\n",
    "    show_plot(gridplot(grid), '3-grade-correlations.png')\n",
    "\n",
    "def check_binning_tau():\n",
    "    split_fns = {\n",
    "        'ceil': ceil,\n",
    "        'floor': floor,\n",
    "        'random': (lambda x: x if x == int(x) else floor(x) + randrange(2)),\n",
    "        'to-0': (lambda x: floor(x) if x > 0 else ceil(x)),\n",
    "        'to-1': (lambda x: floor(x) if x > 1 else ceil(x)),\n",
    "        'to-2': (lambda x: floor(x) if x > 2 else ceil(x)),\n",
    "        'to-3': (lambda x: floor(x) if x > 3 else ceil(x)),\n",
    "        'to-4': (lambda x: floor(x) if x > 4 else ceil(x)),\n",
    "        'to-5': (lambda x: floor(x) if x > 5 else ceil(x)),\n",
    "    }\n",
    "    fys_df = pd.concat([\n",
    "        TWE_DATA[['assessment', 'fall_grade', 'fall_gpa', 'spring_grade', 'spring_gpa', 'twe']].rename(columns={'twe':'score'}),\n",
    "        PORT_DATA[['assessment', 'fall_grade', 'fall_gpa', 'spring_grade', 'spring_gpa', 'mean']].rename(columns={'mean':'score'}),\n",
    "    ])\n",
    "    fys_df = fys_df.dropna() # FIXME why is this necessary?\n",
    "    rows = []\n",
    "    for name, split_fn in split_fns.items():\n",
    "        df = create_fys_correlation_df(fys_df.copy(), 'portfolio', split_fn=split_fn)\n",
    "        for semester in ['fall', 'spring']:\n",
    "            rows.append([name, semester, kendalls_tau(df, semester)])\n",
    "    return (\n",
    "        pd.DataFrame(rows, columns=['method', 'semester', 'tau'])\n",
    "        .pivot_table(index=['method'], columns=['semester'])\n",
    "        .droplevel(0, axis=1)\n",
    "    )\n",
    "\n",
    "hide_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aac241",
   "metadata": {},
   "source": [
    "Note that some TWE scores are NANs; why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fys_correlations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7cb13",
   "metadata": {},
   "source": [
    "Reasons why correlation is low:\n",
    "* course grades include non-writing components (eg. participation, knowledge-based content, etc.)\n",
    "* FIXME\n",
    "\n",
    "Areas of concern:\n",
    "\n",
    "1. There are more years of TWE than of the portfolio (and since FYS switched to S/U, we will never get more data for the latter)\n",
    "2. There are finer distinctions in the portfolio, due to averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50205b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_binning_tau()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
